{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Patrick Ng  \n",
    "Class: W261-2  \n",
    "Date: Mar 19, 2016  \n",
    "HW09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW 9.0: Short answer questions\n",
    "\n",
    "What is PageRank and what is it used for in the context of web search?  \n",
    "What modifications have to be made to the webgraph in order to leverage the machinery of Markov Chains to \n",
    "compute the steady state distibuton?  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is PageRank and what is it used for in the context of web search?  \n",
    "PageRank is a link analysis algorithm and it assigns a numerical weighting to each element of a hyperlinked set of documents, such as the World Wide Web, with the purpose of \"measuring\" its relative importance within the set.  In the context of web search, it is used for ranking the documents in the posting list of the inverted index, so that relatively more important documents will be put at the beginning of the posting list.  \n",
    "  \n",
    "#### What modifications have to be made to the webgraph in order to leverage the machinery of Markov Chains to compute the steady state distibuton?  \n",
    "In order to leverage the machinery of Markov Chains to compute the steady state distibuton, we need to make two adjustments to the webgraph (i.e. the transition matrix H, where each row represents a node):\n",
    "+ **Stochasticity adjustment** to resolve dangling nodes (nodes with no outbound links) problem:\n",
    "    + For each zero row we replace each element with 1/n, where n is the number of nodes in the wegraph.\n",
    "+ **Primitivity adjustment** to guarantee convergence.\n",
    "    + We need to define a teleport probability $\\alpha$ and define the transition matrix as:  \n",
    "<br/>\n",
    "\\begin{equation} \n",
    "P = (1-\\alpha)H + {\\alpha}I(1/n)  \n",
    "\\end{equation}  \n",
    "where:  \n",
    "        - _H_ is the hyperlink matrix\n",
    "        - n is the number of nodes in the webgraph\n",
    "        - I is the identity matrix\n",
    "        \n",
    "#### OPTIONAL: In topic-specific pagerank, how can we insure that the irreducible property is satified? (HINT: see HW9.4)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HW 9.1: MRJob implementation of basic PageRank\n",
    "\n",
    "Write a basic MRJob implementation of the iterative PageRank algorithm\n",
    "that takes sparse adjacency lists as input (as explored in HW 7).\n",
    "Make sure that you implementation utilizes teleportation (1-damping/the number of nodes in the network), \n",
    "and further, distributes the mass of dangling nodes with each iteration\n",
    "so that the output of each iteration is correctly normalized (sums to 1).  \n",
    "\n",
    "NOTE: \n",
    "+ The PageRank algorithm assumes that a random surfer (walker), starting from a random web page,\n",
    "chooses the next page to which it will move by clicking at random, with probability d,\n",
    "one of the hyperlinks in the current page. This probability is represented by a so-called\n",
    "‘damping factor’ d, where d ∈ (0, 1). Otherwise, with probability (1 − d), the surfer\n",
    "jumps to any web page in the network. If a page is a dangling end, meaning it has no\n",
    "outgoing hyperlinks, the random surfer selects an arbitrary web page from a uniform\n",
    "distribution and “teleports” to that page]\n",
    "\n",
    "\n",
    "As you build your code, use the test data\n",
    "\n",
    "s3://ucb-mids-mls-networks/PageRank-test.txt\n",
    "Or under the Data Subfolder for HW7 on Dropbox with the same file name.  \n",
    "(On Dropbox https://www.dropbox.com/sh/2c0k5adwz36lkcw/AAAAKsjQfF9uHfv-X9mCqr9wa?dl=0)\n",
    "\n",
    "with teleportation parameter set to 0.15 (1-d, where d, the damping factor is set to 0.85), and crosscheck\n",
    "your work with the true result, displayed in the first image\n",
    "in the Wikipedia article:\n",
    "\n",
    "https://en.wikipedia.org/wiki/PageRank\n",
    "\n",
    "and here for reference are the corresponding PageRank probabilities:\n",
    "```\n",
    "A,0.033\n",
    "B,0.384\n",
    "C,0.343\n",
    "D,0.039\n",
    "E,0.081\n",
    "F,0.039\n",
    "G,0.016\n",
    "H,0.016\n",
    "I,0.016\n",
    "J,0.016\n",
    "K,0.016\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the graph structure based on the adjaceny list file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting MrInitGraph.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile MrInitGraph.py\n",
    "import re\n",
    "from mrjob.job import MRJob, MRStep\n",
    "import mrjob\n",
    "import json\n",
    "import sys\n",
    "\n",
    "class MrInitGraph(MRJob):\n",
    "\n",
    "    SORT_VALUES = True  # Need 2nd sort\n",
    "   \n",
    "    def mapper(self, _, line):\n",
    "        # input format:\n",
    "        # Json object:\n",
    "        # 1       {'2': 1, '6': 1}\n",
    "        \n",
    "        fields = line.strip().split('\\t')\n",
    "        node = fields[0]\n",
    "\n",
    "        # JSON uses double quote for string\n",
    "        adjList = json.loads(fields[1].replace(\"'\", '\"'))\n",
    "        \n",
    "        # Output for the node, which is an outbound node\n",
    "        yield node, [0, adjList] # 0 is used for 2nd sorting\n",
    "        \n",
    "        # Also need to output an empty entry for every nodes in the adjList.\n",
    "        # It is needed for directed graph, so that in the reducer we can generate \n",
    "        # an entry for nodes which don't have an outbound link.\n",
    "        for key in adjList.keys():\n",
    "            yield key, [1]  # 1 is used for 2nd sorting\n",
    "            \n",
    "    def reducer(self, node, values):\n",
    "        value = values.next()\n",
    "        \n",
    "        # An outbound node will be seen first because we use 2nd sorting\n",
    "        if value[0] == 0:\n",
    "            # It's an outbound record.  \n",
    "            # Just yield the node without processing the rest of values.\n",
    "            yield node, [value[1:], 0]\n",
    "        else:\n",
    "            # In a directed graph, if a node has no outbound link, generate an entry for it.\n",
    "            # And ignore the rest of values\n",
    "            yield node, [{}, 0]\n",
    "                                                              \n",
    "if __name__ == '__main__':\n",
    "    MrInitGraph.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the number of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting MrFindNumberOfNodes.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile MrFindNumberOfNodes.py\n",
    "import re\n",
    "from mrjob.job import MRJob, MRStep\n",
    "import mrjob\n",
    "import json\n",
    "import sys\n",
    "\n",
    "class MrFindNumberOfNodes(MRJob):\n",
    "    \n",
    "    def steps(self):\n",
    "        return [MRStep(mapper_init=self.mapper_init, mapper=self.mapper, mapper_final = self.mapper_final,\n",
    "                   combiner = self.reducer,\n",
    "                   reducer=self.reducer\n",
    "            )]\n",
    "\n",
    "    def mapper_init(self):\n",
    "        self.partial_size = 0\n",
    "        \n",
    "    def mapper(self, _, line):\n",
    "        self.partial_size += 1\n",
    "        \n",
    "    def mapper_final(self):\n",
    "        yield None, self.partial_size\n",
    "        \n",
    "    def reducer(self, key, values):\n",
    "        yield None, sum(values)\n",
    "                                                              \n",
    "if __name__ == '__main__':\n",
    "    MrFindNumberOfNodes.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A PageRank iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing MrPageRankIteration.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile MrPageRankIteration.py\n",
    "import re\n",
    "from mrjob.job import MRJob, MRStep\n",
    "import mrjob\n",
    "import json\n",
    "import sys\n",
    "\n",
    "class MrPageRankIteration(MRJob):\n",
    "\n",
    "    INPUT_PROTOCOL = mrjob.protocol.JSONProtocol\n",
    "    \n",
    "    Type_Graph = 0\n",
    "    Type_PR = 1\n",
    "    \n",
    "    Key_LostPR = \"#\"\n",
    "    \n",
    "    def configure_options(self):\n",
    "        super(MrInitPageRank, self).configure_options()\n",
    "        self.add_passthrough_option(\n",
    "            '--initWithGraphSize', type='int', default=None)\n",
    "\n",
    "    def mapper_init(self):\n",
    "        self.lostPR = 0\n",
    "        \n",
    "    def mapper(self, node, data):\n",
    "        adjList, pageRank = data\n",
    "        \n",
    "        # We're at the first iteration, and PageRank value hasn't been initialized yet.\n",
    "        if self.options.initWithGraphSize is not None:\n",
    "            pageRank = 1 / self.options.initWithGraphSize\n",
    "\n",
    "        # Pass along the graph structure\n",
    "        yield node, [self.Type_Graph, adjList]\n",
    "        \n",
    "        if len(adjList) > 0:\n",
    "            # The PR juice we will send out\n",
    "            p = pageRank / len(adjList)\n",
    "            for link in adjList.keys():\n",
    "                yield link, [self.Type_PR, p] # 1 means it's a PR contribution\n",
    "        else:\n",
    "            self.lostPR += pageRank\n",
    "            \n",
    "    def mapper_final(self):\n",
    "        yield self.Key_LostPR, self.lostPR\n",
    "\n",
    "    def reducer(self, node, values):\n",
    "        pageRank = 0\n",
    "        for value in values:\n",
    "            valueType, data = value\n",
    "            if valueType == self.Type_Graph:\n",
    "                adjList = data\n",
    "            else:\n",
    "                pageRank += float(data)\n",
    "\n",
    "        # Note: we haven't handled lostPR yet!!!!!!\n",
    "        yield node, [adjList, pageRank]\n",
    "            \n",
    "                                                              \n",
    "if __name__ == '__main__':\n",
    "    MrPageRankIteration.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Driver for HW91"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Driver_Hw91.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Driver_Hw91.py\n",
    "from MrFindNumberOfNodes import MrFindNumberOfNodes\n",
    "from MrInitGraph import MrInitGraph\n",
    "import time\n",
    "\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--inputFile\", type=str)\n",
    "parser.add_argument(\"--ec2-instance-type\", type=str, default=None)\n",
    "parser.add_argument(\"--initGraphFolder\", type=str, default=None)\n",
    "parser.add_argument(\"--num-ec2-instances\", type=str, default=None)\n",
    "parser.add_argument(\"-r\", \"--run\", type=str)\n",
    "args = parser.parse_args()\n",
    "\n",
    "jobArgsBase = ['-r', args.run,\n",
    "             '--no-strict-protocols']\n",
    "\n",
    "if args.run == \"emr\":\n",
    "    jobArgsBase += [\"--pool-emr-job-flows\"]\n",
    "    \n",
    "    if args.ec2_instance_type is not None:\n",
    "        jobArgsBase += [\"--ec2-instance-type\", args.ec2_instance_type]\n",
    "        \n",
    "    if args.num_ec2_instances is not None:\n",
    "        jobArgsBase += [\"--num-ec2-instances\", args.num_ec2_instances]\n",
    "\n",
    "i = 1\n",
    "startTime = time.time()\n",
    "\n",
    "def ensureFolderPath(path):\n",
    "    return path if path.endswith(\"/\") else path + \"/\"\n",
    "\n",
    "# Initialize the graph structure\n",
    "mr_jobInitGraph = MrInitGraph(args=[args.inputFile] + jobArgsBase)\n",
    "with mr_jobInitGraph.make_runner() as runner: \n",
    "    runner.run()\n",
    "\n",
    "    if args.run == \"inline\" or args.run == \"local\":\n",
    "        initGraphFile = \"_initGraph.txt\"\n",
    "    else:\n",
    "        initGraphFile = ensureFolderPath(args.initGraphFolder)\n",
    "        jobArgs += [\"--no-output\", \"--output-dir\", interSsspFile]\n",
    "\n",
    "    if args.run == \"inline\" or args.run == \"local\":\n",
    "        # Generate the initGraph file\n",
    "        with open(initGraphFile, 'w') as f:            \n",
    "            for line in runner.stream_output():\n",
    "                f.write(\"%s\" % (line))\n",
    "    \n",
    "# Find the number of nodes\n",
    "mr_jobNumberOfNodes = MrFindNumberOfNodes(args=[initGraphFile] + jobArgsBase)\n",
    "with mr_jobNumberOfNodes.make_runner() as runner: \n",
    "    runner.run()\n",
    "\n",
    "    for line in runner.stream_output():\n",
    "        key, value =  mr_jobNumberOfNodes.parse_output_line(line)\n",
    "        nodeCount = int(value)\n",
    "    \n",
    "    print \"Number of nodes = %d\" % (nodeCount)\n",
    "\n",
    "print\n",
    "print \"Total time: %d sec\" % (time.time() - startTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No handlers could be found for logger \"mrjob.sim\"\n",
      "Number of nodes = 11\n",
      "\n",
      "Total time: 0 sec\n"
     ]
    }
   ],
   "source": [
    "!python Driver_Hw91.py -r inline --inputFile PageRank-test.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
