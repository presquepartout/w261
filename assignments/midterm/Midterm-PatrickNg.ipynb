{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Patrick Ng  \n",
    "Email: patng@ischool.berkeley.edu  \n",
    "Class: W261-2  \n",
    "Midterm  \n",
    "Date of submission: Mar 2, 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing kltext.txt\n"
     ]
    }
   ],
   "source": [
    "%%writefile kltext.txt\n",
    "1.Data Science is an interdisciplinary field about processes and systems to extract knowledge or insights from large volumes of data in various forms (data in various forms, data in various forms, data in various forms), either structured or unstructured,[1][2] which is a continuation of some of the data analysis fields such as statistics, data mining and predictive analytics, as well as Knowledge Discovery in Databases.\n",
    "2.Machine learning is a subfield of computer science[1] that evolved from the study of pattern recognition and computational learning theory in artificial intelligence.[1] Machine learning explores the study and construction of algorithms that can learn from and make predictions on data.[2] Such algorithms operate by building a model from example inputs in order to make data-driven predictions or decisions,[3]:2 rather than following strictly static program instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MRjob class for calculating pairwise similarity using K-L Divergence as the similarity measure\n",
    "\n",
    "Job 1: create inverted index (assume just two objects) <P>\n",
    "Job 2: calculate the similarity of each pair of objects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting kldivergence.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile kldivergence.py\n",
    "from mrjob.job import MRJob\n",
    "import re\n",
    "import numpy as np\n",
    "class kldivergence(MRJob):\n",
    "    def mapper1(self, _, line):\n",
    "        index = int(line.split('.',1)[0])\n",
    "        letter_list = re.sub(r\"[^A-Za-z]+\", '', line).lower()\n",
    "        count = {}\n",
    "        for l in letter_list:\n",
    "            if count.has_key(l):\n",
    "                count[l] += 1\n",
    "            else:\n",
    "                count[l] = 1\n",
    "        for key in count:\n",
    "            yield key, [index, count[key]*1.0/len(letter_list)]\n",
    "\n",
    "\n",
    "    def reducer1(self, key, values):\n",
    "        yield key, values\n",
    "    \n",
    "    def reducer2(self, key, values):\n",
    "        kl_sum = 0\n",
    "        for value in values:\n",
    "            kl_sum = kl_sum + value\n",
    "        yield None, kl_sum\n",
    "            \n",
    "    def steps(self):\n",
    "        return [self.mr(mapper=self.mapper1,\n",
    "                        reducer=self.reducer1),\n",
    "                self.mr(reducer=self.reducer2)]\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    kldivergence.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:mrjob.runner:\n",
      "WARNING:mrjob.runner:PLEASE NOTE: Starting in mrjob v0.5.0, protocols will be strict by default. It's recommended you run your job with --strict-protocols or set up mrjob.conf as described at https://pythonhosted.org/mrjob/whats-new.html#ready-for-strict-protocols\n",
      "WARNING:mrjob.runner:\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n",
      "WARNING:mrjob.job:mr() is deprecated and will be removed in v0.6.0. Use mrjob.step.MRStep directly instead.\n"
     ]
    }
   ],
   "source": [
    "from kldivergence import kldivergence\n",
    "mr_job = kldivergence(args=['kltext.txt'])\n",
    "with mr_job.make_runner() as runner: \n",
    "    runner.run()\n",
    "    # stream_output: get access of the output \n",
    "    for line in runner.stream_output():\n",
    "        print mr_job.parse_output_line(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weighted K-means ##\n",
    "```\n",
    "Write a MapReduce job in MRJob to do the training at scale of a weighted K-means algorithm.\n",
    "\n",
    "You can write your own code or you can use most of the code from the following notebook:\n",
    "\n",
    "http://nbviewer.ipython.org/urls/dl.dropbox.com/s/kjtdyi10nwmk4ko/MrJobKmeans-MIDS-Midterm.ipynb\n",
    "https://www.dropbox.com/s/kjtdyi10nwmk4ko/MrJobKmeans-MIDS-Midterm.ipynb?dl=0\n",
    "\n",
    "Weight each example as follows using the inverse vector length (Euclidean norm): \n",
    "\n",
    "weight(X)= 1/||X||, \n",
    "\n",
    "where ||X|| = SQRT(X.X)= SQRT(X1^2 + X2^2)\n",
    "\n",
    "Here X is vector made up of X1 and X2.\n",
    "\n",
    "Using the following data answer the following questions:\n",
    "\n",
    "https://www.dropbox.com/s/ai1uc3q2ucverly/Kmeandata.csv?dl=0\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting Kmeans.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile Kmeans.py\n",
    "from __future__ import division\n",
    "from numpy import argmin, array, random\n",
    "from mrjob.job import MRJob, MRStep\n",
    "from itertools import chain\n",
    "from math import sqrt\n",
    "\n",
    "def distance(datapoint, centroid_point):\n",
    "    datapoint = array(datapoint)\n",
    "    centroid_points = array(centroid_point)\n",
    "    diff = datapoint - centroid_points \n",
    "    diffsq = diff**2\n",
    "    distance = (diffsq.sum(axis = 0))**0.5\n",
    "    return distance\n",
    "\n",
    "#Calculate find the nearest centroid for data point \n",
    "def MinDist(datapoint, centroid_points):\n",
    "    datapoint = array(datapoint)\n",
    "    centroid_points = array(centroid_points)\n",
    "    diff = datapoint - centroid_points \n",
    "    diffsq = diff**2\n",
    "    \n",
    "    distances = (diffsq.sum(axis = 1))**0.5\n",
    "    # Get the nearest centroid for each instance\n",
    "    min_idx = argmin(distances)\n",
    "    return min_idx\n",
    "\n",
    "#Check whether centroids converge\n",
    "def stop_criterion(centroid_points_old, centroid_points_new,T):\n",
    "    oldvalue = list(chain(*centroid_points_old))\n",
    "    newvalue = list(chain(*centroid_points_new))\n",
    "    Diff = [abs(x-y) for x, y in zip(oldvalue, newvalue)]\n",
    "    Flag = True\n",
    "    for i in Diff:\n",
    "        if(i>T):\n",
    "            Flag = False\n",
    "            break\n",
    "    return Flag\n",
    "\n",
    "\n",
    "class MRKmeans(MRJob):\n",
    "    centroid_points=[]\n",
    "    k=3    \n",
    "    def steps(self):\n",
    "        return [\n",
    "            MRStep(mapper_init = self.mapper_init, \n",
    "                   mapper=self.mapper,\n",
    "                   #combiner = self.combiner,  # Can't use combiner for MT11\n",
    "                   reducer_init = self.reducer_init,\n",
    "                   reducer=self.reducer,\n",
    "                   reducer_final = self.reducer_final\n",
    "                )\n",
    "               ]\n",
    "    #load centroids info from file\n",
    "    def mapper_init(self):\n",
    "        self.centroid_points = [map(float,s.split('\\n')[0].split(',')) for s in open(\"Centroids.txt\").readlines()]\n",
    "        open('Centroids.txt', 'w').close()\n",
    "        \n",
    "    #load data and output the nearest centroid index and data point \n",
    "    def mapper(self, _, line):\n",
    "        D = (map(float,line.split(',')))\n",
    "        idx = MinDist(D,self.centroid_points)\n",
    "        # weight(X)= 1/||X||, \n",
    "        # where ||X|| = SQRT(X.X)= SQRT(X1^2 + X2^2)\n",
    "        x1 = D[0]\n",
    "        x2 = D[1]\n",
    "        weight = sqrt(x1**2 + x2**2)\n",
    "        \n",
    "        yield int(idx), (x1*weight, x2*weight, weight)\n",
    "        \n",
    "    def reducer_init(self):\n",
    "        self.weight_sum = 0.0\n",
    "        self.weighted_distance_sum = 0.0\n",
    "        \n",
    "    #Aggregate sum for each cluster and then calculate the new centroids\n",
    "    def reducer(self, idx, inputdata): \n",
    "        centroids = []\n",
    "        num = [0]*self.k \n",
    "        distances = 0\n",
    "        allX = []\n",
    "        allY = []\n",
    "        weights = []\n",
    "        \n",
    "        for i in range(self.k):\n",
    "            centroids.append([0,0])\n",
    "            \n",
    "        for x, y, n in inputdata:\n",
    "            num[idx] = num[idx] + n\n",
    "            centroids[idx][0] = centroids[idx][0] + x\n",
    "            centroids[idx][1] = centroids[idx][1] + y\n",
    "            allX.append(x)\n",
    "            allY.append(y)\n",
    "            weights.append(n)\n",
    "            \n",
    "        centroids[idx][0] = centroids[idx][0]/num[idx]\n",
    "        centroids[idx][1] = centroids[idx][1]/num[idx]\n",
    "        \n",
    "        # Calculate partial sum of weighted_distance_i and weight_i\n",
    "        self.weight_sum += num[idx]\n",
    "        for x,y,n in zip(allX, allY, weights):\n",
    "            self.weighted_distance_sum += \\\n",
    "                distance([x,y], [centroids[idx][0], centroids[idx][1]]) * n\n",
    "            \n",
    "        with open('Centroids.txt', 'a') as f:\n",
    "            f.writelines(str(centroids[idx][0]) + ',' + str(centroids[idx][1]) + '\\n')\n",
    "            \n",
    "        yield idx,(centroids[idx][0],centroids[idx][1])\n",
    "        \n",
    "    def reducer_final(self):\n",
    "        yield None, (self.weighted_distance_sum/self.weight_sum)\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    MRKmeans.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Driver ####\n",
    "\n",
    "Generate random initial centroids\n",
    "\n",
    "New Centroids = initial centroids\n",
    "\n",
    "While(1)：\n",
    "+ Cacluate new centroids\n",
    "+ stop if new centroids close to old centroids\n",
    "+ Updates centroids "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration1:\n",
      "0 [-3.9707251767434597, 0.24753995934048853]\n",
      "1 [5.559358757604786, 0.13140683641026107]\n",
      "2 [0.21319986473145544, 5.559691555704146]\n",
      "None 27.0864343044\n",
      "\n",
      "\n",
      "iteration2:\n",
      "0 [-5.273661830097599, 0.01778068820189739]\n",
      "1 [5.315666040265944, -0.0191245246454466]\n",
      "2 [0.07760590556533625, 5.322298286870532]\n",
      "None 26.2940010771\n",
      "\n",
      "\n",
      "iteration3:\n",
      "0 [-5.29872166540091, -0.006290282704146047]\n",
      "1 [5.315666040265944, -0.0191245246454466]\n",
      "2 [0.05740025819123362, 5.3015009631419545]\n",
      "None 26.2896202234\n",
      "\n",
      "\n",
      "iteration4:\n",
      "0 [-5.29872166540091, -0.006290282704146047]\n",
      "1 [5.315666040265944, -0.0191245246454466]\n",
      "2 [0.05740025819123362, 5.3015009631419545]\n",
      "None 26.2896202234\n",
      "\n",
      "\n",
      "iteration5:\n",
      "0 [-5.29872166540091, -0.006290282704146047]\n",
      "1 [5.315666040265944, -0.0191245246454466]\n",
      "2 [0.05740025819123362, 5.3015009631419545]\n",
      "None 26.2896202234\n",
      "\n",
      "\n",
      "iteration6:\n",
      "0 [-5.29872166540091, -0.006290282704146047]\n",
      "1 [5.315666040265944, -0.0191245246454466]\n",
      "2 [0.05740025819123362, 5.3015009631419545]\n",
      "None 26.2896202234\n",
      "\n",
      "\n",
      "iteration7:\n",
      "0 [-5.29872166540091, -0.006290282704146047]\n",
      "1 [5.315666040265944, -0.0191245246454466]\n",
      "2 [0.05740025819123362, 5.3015009631419545]\n",
      "None 26.2896202234\n",
      "\n",
      "\n",
      "iteration8:\n",
      "0 [-5.29872166540091, -0.006290282704146047]\n",
      "1 [5.315666040265944, -0.0191245246454466]\n",
      "2 [0.05740025819123362, 5.3015009631419545]\n",
      "None 26.2896202234\n",
      "\n",
      "\n",
      "iteration9:\n",
      "0 [-5.29872166540091, -0.006290282704146047]\n",
      "1 [5.315666040265944, -0.0191245246454466]\n",
      "2 [0.05740025819123362, 5.3015009631419545]\n",
      "None 26.2896202234\n",
      "\n",
      "\n",
      "iteration10:\n",
      "0 [-5.29872166540091, -0.006290282704146047]\n",
      "1 [5.315666040265944, -0.0191245246454466]\n",
      "2 [0.05740025819123362, 5.3015009631419545]\n",
      "None 26.2896202234\n",
      "\n",
      "\n",
      "Centroids\n",
      "\n",
      "[[-5.29872166540091, -0.006290282704146047], [5.315666040265944, -0.0191245246454466], [0.05740025819123362, 5.3015009631419545]]\n"
     ]
    }
   ],
   "source": [
    "from numpy import random, array\n",
    "from Kmeans import MRKmeans, stop_criterion\n",
    "mr_job = MRKmeans(args=['Kmeandata.csv', '--file', 'Centroids.txt',\n",
    "                       '--strict-protocols', '-r', 'inline'])\n",
    "\n",
    "#Geneate initial centroids\n",
    "centroid_points = [[0,0],[6,3],[3,6]]\n",
    "k = 3\n",
    "with open('Centroids.txt', 'w+') as f:\n",
    "        f.writelines(','.join(str(j) for j in i) + '\\n' for i in centroid_points)\n",
    "\n",
    "# Update centroids iteratively\n",
    "for i in range(10):\n",
    "    # save previous centoids to check convergency\n",
    "    centroid_points_old = centroid_points[:]\n",
    "    print \"iteration\"+str(i+1)+\":\"\n",
    "    with mr_job.make_runner() as runner: \n",
    "        runner.run()\n",
    "        # stream_output: get access of the output \n",
    "        for line in runner.stream_output():\n",
    "            key,value =  mr_job.parse_output_line(line)\n",
    "            print key, value\n",
    "            if key is not None:\n",
    "                centroid_points[key] = value\n",
    "    print \"\\n\"\n",
    "    i = i + 1\n",
    "print \"Centroids\\n\"\n",
    "print centroid_points\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MT11. ###\n",
    "Using the result of the previous question, which number below is the closest \n",
    "to the average weighted distance between each example and its assigned (closest) centroid?\n",
    "The average weighted distance is defined as  \n",
    "\n",
    "`sum over i  (weighted_distance_i)     /  sum over i (weight_i)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
