{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Patrick Ng  \n",
    "Email: patng@ischool.berkeley.edu  \n",
    "Class: W261-2  \n",
    "Week: 01  \n",
    "Date of submission:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>HW1.0.0.</u>  \n",
    "**Big data** is broad term for data sets so large or complex that traditional data-processing applications are inadequate.  IBM has characterized big data by its 4 V's: Volume (scale of data), Velocity (analysis of streaming data), Variety (different forms of data) and Veractiy (uncertainty of data). \n",
    "\n",
    "For example, for a popular website which attracts ten millions visits each day, the amount of web log data generated each day is about 50GB.  The website also uses a recommendation engine to generate recommendations to the visitors.  In order to train the engine each night, we need to cleanse (e.g. remove logs generated by suspected robots) and transform the web log data into a format usable by the training process, and the training itself has to process all the new web log data, together with all data generated from the past.  The whole process has to complete within 6 hours due to business needs.  However, using traditional data-processing techniques the whole proceess could take more than 8 hours.  As a result, we need to make use of big data techniques such as HDFS and parallel computating in order to complete the processing within the required period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>HW1.0.1.</u>  \n",
    "To estimate the bias, the variance, the irreduciable error for a test dataset T when using polynomial regression models of degree 1, 2, 3, 4 and 5, the high level strategy is:\n",
    "- Please note that each regression model will produce an estimator <i>g(x)</i> of the true function <i>f(x)</i>.\n",
    "- For each model:\n",
    "    - Using bootstrapping, generate datasets S<sub>1</sub>, S<sub>2</sub>, ..., S<sub>B</sub> from the dataset T.\n",
    "    - For each S<sub>b</sub>:\n",
    "      - Use S<sub>b</sub> to train the model to produce an estimator g<sub>b</sub>(x).\n",
    "      - Let the dataset T<sub>b</sub> = T \\ S<sub>b</sub> be the data points that do not appear in S<sub>b</sub>\n",
    "      - Calculate the predicted value g<sub>b</sub>(x) for each x in T<sub>b</sub>.\n",
    "    - This way we produce B estimators.  Average them out will produce the average estimator E[g(x)].\n",
    "  - We then calculate the bias, the variance and the irreduciable error of each model:\n",
    "    - For each estimaor\n",
    "    - Bias:\n",
    "      - The formula is: Bias = E[g(x)] - f(x)\n",
    "      - But "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>HW1.1.</u>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "HW1.1. Read through the provided control script (pNaiveBayes.sh)\n",
    "and all of its comments. When you are comfortable with their\n",
    "purpose and function, respond to the remaining homework questions below. \n",
    "'''\n",
    "print \"done\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<u>HW1.2.</u>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting mapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile mapper.py\n",
    "#!/usr/bin/python\n",
    "## mapper.py\n",
    "## Author: Patrick Ng\n",
    "## Description: mapper code for HW1.2\n",
    "\n",
    "import sys\n",
    "import re\n",
    "\n",
    "## collect user input\n",
    "filename = sys.argv[1]\n",
    "findwords = re.split(\" \",sys.argv[2].lower())\n",
    "\n",
    "findword = findwords[0] # for HW1.2 we handle only a single word\n",
    "count = 0\n",
    "\n",
    "with open(filename, 'r') as f:\n",
    "    for line in f:\n",
    "        parts = re.split(\"\\t\", line)\n",
    "        text = parts[2] + \" \" + parts[3] # Subjects and contents\n",
    "        count += text.count(findword)\n",
    "        print '##########################'\n",
    "        #print text\n",
    "        #count += count1\n",
    "        #print count1, \",\", count\n",
    "\n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting reducer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile reducer.py\n",
    "#!/usr/bin/python\n",
    "## mapper.py\n",
    "## Author: Patrick Ng\n",
    "## Description: reducer code for HW1.2\n",
    "\n",
    "import sys\n",
    "import re\n",
    "\n",
    "## collect user input\n",
    "filenames = sys.argv[1:]\n",
    "\n",
    "count = 0\n",
    "\n",
    "for filename in filenames:\n",
    "    with open(filename, 'r') as f:\n",
    "        line = f.readline()\n",
    "        count += int(line)\n",
    "\n",
    "print count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!chmod +x mapper.py; chmod +x reducer.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
